{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Sakila Data Agent Guide 📊\n",
    "\n",
    "In this notebook we will develop the neccessary functions to build a Sakila Data AI Agent based on the OpenAI API.\n",
    "\n",
    "- We will cover the following topics:\n",
    "\n",
    "    1. ChatGPT API call\n",
    "    2. System Prompts\n",
    "    3. Tool Calls\n",
    "    4. Tool Call Parsing\n",
    "    5. SQL Data Querying Tool\n",
    "    6. Create the Sakila Data Agent\n",
    "\n",
    "- To run the OpenAI API you will need to add an API key to a `.env` file. Also, provide the database credentials. use the `.env.sample` file as a template, remember to rename it to `.env` after cloning the repository.\n",
    "\n",
    "- Relevant Docs: [OpenAI API Documentation](https://platform.openai.com/docs/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install the OpenAI library\n",
    "- Let's start by installing the OpenAI library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.12/site-packages (1.84.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "- Now let's import the necessary libraries for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # for parsing the JSON responses from the OpenAI API, we'll see more about this later\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries & functions to pretty print text and JSON responses, just needed for the notebook\n",
    "import textwrap # Text wrapping\n",
    "from pprint import pprint # Pretty printing json\n",
    "\n",
    "def pretty_print(response):\n",
    "    if isinstance(response, (str, dict)):\n",
    "        print(textwrap.fill(response, width=80))\n",
    "    else:\n",
    "        response_dict = response.model_dump()\n",
    "        pprint(response_dict, width=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ChatGPT API call\n",
    "\n",
    "+ [OpenAI Quickstart](https://platform.openai.com/docs/quickstart)\n",
    "\n",
    "Find below the basic ChatGPT Chat Completion API call. It has 3 parameters:\n",
    "1. `model`: the model to use, in this case `'gpt-4o-mini'`\n",
    "2. `messages`: the list of messages to send to the model, here is where the conversation history is passed. The first message is the system prompt, and the rest is the alternating conversation between the user and the assistant.   \n",
    "    - The system prompt: the initial and instructions for the model\n",
    "    - The user prompt: the question or task for the model\n",
    "3. `tools`: the available tools to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client, the API key is automatically loaded from the .env file\n",
    "client = OpenAI()\n",
    "\n",
    "# Make a basic ChatGPT API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools= None,\n",
    "    messages=[\n",
    "        {   \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        }, # The system prompt is always the first message\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Which country has the most bordering countries?\" # User prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Access the response from the LLM\n",
    "response = completion.choices[0].message # The response from the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [],\n",
      " 'audio': None,\n",
      " 'content': 'The country with the most bordering countries is China, which '\n",
      "            'shares its borders with 14 different countries. These countries '\n",
      "            'are India, Russia, Mongolia, Pakistan, Nepal, Bhutan, '\n",
      "            'Afghanistan, Tajikistan, Kyrgyzstan, and Kazakhstan, as well as '\n",
      "            'the Special Administrative Regions of Hong Kong and Macau, which '\n",
      "            'have borders with neighboring regions of countries. \\n'\n",
      "            '\\n'\n",
      "            'In addition, Brazil also shares borders with 10 countries and is '\n",
      "            'notable for having the most neighboring countries in South '\n",
      "            'America. However, the record for the most total bordering '\n",
      "            'countries is held by China.',\n",
      " 'function_call': None,\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': None}\n"
     ]
    }
   ],
   "source": [
    "# Print the chat completion response\n",
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chat completion `response` JSON object above has 2 keys we will be working with:\n",
    "1. `content`: the text response from the LLM\n",
    "2. `tool_calls`: the tool calls made by the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. System Prompt\n",
    "\n",
    "[OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "\n",
    "+ System prompts are a way to <u>guide the AI's behavior</u>. They are a part of the prompt that is sent to the AI.\n",
    "+ The system prompt is sent to the AI at the beginning of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant and an expert data analyst that can answer questions about the sakila database. Respond in a very formal and concise way.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# Make a basic ChatGPT API call\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {   \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who are you?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [],\n",
      " 'audio': None,\n",
      " 'content': 'I am an expert data analyst with specialized knowledge of the '\n",
      "            'Sakila database. I am here to assist you by providing insights '\n",
      "            'and answering questions related to this database. How may I '\n",
      "            'assist you today?',\n",
      " 'function_call': None,\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': None}\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tool Calling\n",
    "\n",
    "[OpenAI Function Calling Docs](https://platform.openai.com/docs/guides/function-calling)\n",
    "\n",
    "### What are tool calls?\n",
    "+ Tool calling is a way to <u>extend the capabilities of the AI</u>.\n",
    "+ It allows the AI to execute functions and return the results.\n",
    "+ It is a way to <u>integrate external tools</u> into the AI's behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide a tool to the LLM, we need to define two things: \n",
    "1. Tool function schema definition\n",
    "2. A python function to be called when the LLM invokes the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tool Function Definition\n",
    "\n",
    "The tool function definition is a dictionary that describes the tool to the LLM.\n",
    "It has the following keys:\n",
    "1. **type**: the type of the function, it must be `\"function\"`\n",
    "2. **function**: a dictionary with the following keys:\n",
    "    - **name**: the name of the function\n",
    "    - **description**: the description of the function\n",
    "    - **parameters**: the parameters of the function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of tools following the OpenAI's function definition schema\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Python Function to be Called when the LLM invokes the tool\n",
    "\n",
    "This is simply a python function that will be called when the LLM invokes the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a python function to be called when the LLM invokes the tool\n",
    "def get_weather(location):\n",
    "    # Here we simulate the weather function with hardcoded values, just for testing\n",
    "    return f\"The weather in {location} is sunny and 22°C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tool Call Parsing\n",
    "\n",
    "How do tools work?\n",
    "+ When the user asks something that should be answered using one or multiple of the predefined tools, the LLM `response` object will contain a `tool_calls` key with a list of tool calls. The `content` key will be empty.\n",
    "+ Each tool call is a dictionary with the following keys:\n",
    "    - `name`: the name of the tool\n",
    "    - `arguments`: the arguments of the tool\n",
    "+ Then we **parse out the tool call arguments** and execute the python function with the arguments.\n",
    "\n",
    "Now we are ready to test the tool calling and parse the response to get the tool call arguments.\n",
    "\n",
    "What does parsing mean?\n",
    "- Parsing is the process of extracting desired information from a string or a data structure. In this case we want to get the JSON object from the `arguments` key and convert it to a python dictionary. \n",
    "+ JSON Object -> Python Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "# Make a ChatGPT API call with tool calling\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=tools, # here we pass the tools to the LLM\n",
    "    messages=[\n",
    "        {   \"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the current weather in Barcelona?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [],\n",
      " 'audio': None,\n",
      " 'content': None,\n",
      " 'function_call': None,\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [{'function': {'arguments': '{\"location\":\"Barcelona\"}',\n",
      "                              'name': 'get_weather'},\n",
      "                 'id': 'call_pZDSv3QizYltiBSy1MtN72Eg',\n",
      "                 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "pretty_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we examine the response `'tool_calls'`key we can see that the LLM has called the tool `get_weather` with the argument `{\"location\": \"Barcelona\"}`.\n",
    "\n",
    "We can now parse the response to get the tool call arguments and execute the python function to get the actual weather in Barcelona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool arguments: {'location': 'Barcelona'}\n",
      "The weather in Barcelona is sunny and 22°C\n"
     ]
    }
   ],
   "source": [
    "# Check if the response contains a tool call\n",
    "if response.tool_calls:\n",
    "    # Process each tool call\n",
    "    for tool_call in response.tool_calls:\n",
    "        # Get the tool call arguments\n",
    "        tool_call_arguments = json.loads(tool_call.function.arguments) # Parse the JSON object to a python dictionary\n",
    "        if tool_call.function.name == \"get_weather\":\n",
    "            # Here we call the predefined get_weather function and pass the tool call arguments the LLM provided\n",
    "            print(f\"Tool arguments: {tool_call_arguments}\")\n",
    "            print(get_weather(tool_call_arguments[\"location\"]))\n",
    "else:\n",
    "    pass # To show the assistant response when no tool is called, return the response content here\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SQL Data Querying Tool\n",
    "\n",
    "Now let's create a new tool to get data from the database. It will work like this:\n",
    "1. When the LLM needs to call the tool to get data from the database, it will call the tool and pass the SQL query to be executed.\n",
    "2. The tool will execute the SQL query and return the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Connection to the database using sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /opt/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: sqlalchemy in /opt/anaconda3/lib/python3.12/site-packages (2.0.34)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from sqlalchemy) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection string\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/sakila'\n",
    "# Create the engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PENELOPE</td>\n",
       "      <td>GUINESS</td>\n",
       "      <td>2006-02-15 04:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NICK</td>\n",
       "      <td>WAHLBERG</td>\n",
       "      <td>2006-02-15 04:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ED</td>\n",
       "      <td>CHASE</td>\n",
       "      <td>2006-02-15 04:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>JENNIFER</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>2006-02-15 04:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>JOHNNY</td>\n",
       "      <td>LOLLOBRIGIDA</td>\n",
       "      <td>2006-02-15 04:34:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actor_id first_name     last_name         last_update\n",
       "0         1   PENELOPE       GUINESS 2006-02-15 04:34:33\n",
       "1         2       NICK      WAHLBERG 2006-02-15 04:34:33\n",
       "2         3         ED         CHASE 2006-02-15 04:34:33\n",
       "3         4   JENNIFER         DAVIS 2006-02-15 04:34:33\n",
       "4         5     JOHNNY  LOLLOBRIGIDA 2006-02-15 04:34:33"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the connection\n",
    "query = \"SELECT * FROM actor\"\n",
    "\n",
    "with engine.connect() as connection:    \n",
    "    query = text(query)\n",
    "    result = connection.execute(query)\n",
    "    df = pd.DataFrame(result.all())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create a function to get data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get data from the database\n",
    "def get_data_df(query):\n",
    "    # Create the connection string\n",
    "    password = os.getenv(\"DB_PASSWORD\")\n",
    "    connection_string = 'mysql+pymysql://root:' + password + '@localhost/sakila'\n",
    "    # Create the engine\n",
    "    engine = create_engine(connection_string)\n",
    "    with engine.connect() as connection:    \n",
    "        query = text(query)\n",
    "        result = connection.execute(query)\n",
    "        df = pd.DataFrame(result.all())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city</th>\n",
       "      <th>country_id</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Coruña (La Coruña)</td>\n",
       "      <td>87</td>\n",
       "      <td>2006-02-15 04:45:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Abha</td>\n",
       "      <td>82</td>\n",
       "      <td>2006-02-15 04:45:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>101</td>\n",
       "      <td>2006-02-15 04:45:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Acuña</td>\n",
       "      <td>60</td>\n",
       "      <td>2006-02-15 04:45:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Adana</td>\n",
       "      <td>97</td>\n",
       "      <td>2006-02-15 04:45:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id                  city  country_id         last_update\n",
       "0        1  A Coruña (La Coruña)          87 2006-02-15 04:45:25\n",
       "1        2                  Abha          82 2006-02-15 04:45:25\n",
       "2        3             Abu Dhabi         101 2006-02-15 04:45:25\n",
       "3        4                 Acuña          60 2006-02-15 04:45:25\n",
       "4        5                 Adana          97 2006-02-15 04:45:25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "query = \"SELECT * FROM city\"\n",
    "df = get_data_df(query)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create the Sakila Data Agent\n",
    "\n",
    "Now we can put all the pieces together and create the agent function that will be used in the Streamlit app. Our simple AI agent is composed of 3 elements\n",
    "1. System prompt\n",
    "2. Tools\n",
    "3. Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.sakila_schema import SAKILA_SCHEMA\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "- You are a helpful assistant and an expert data analyst that can answer questions about the sakila database. \n",
    "- Use the get_data_df tool to get the data from the database. \n",
    "- Generate SQL queries following the schema of the database. \n",
    "\n",
    "DATABASE SCHEMA:\n",
    "{SAKILA_SCHEMA}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - You are a helpful assistant and an expert data analyst that can answer\n",
      "questions about the sakila database.  - Use the get_data_df tool to get the data\n",
      "from the database.  - Generate SQL queries following the schema of the database.\n",
      "DATABASE SCHEMA:  ================================================== TABLES IN\n",
      "SAKILA DATABASE ==================================================  - actor -\n",
      "actor_info - address - category - city - country - customer - customer_list -\n",
      "customer_rental_info - customer_rental_payment1 - events - film - film_actor -\n",
      "film_category - film_list - film_text - inventory - language -\n",
      "nicer_but_slower_film_list - payment - rental - sales_by_film_category -\n",
      "sales_by_store - staff - staff_list - store\n",
      "================================================== TABLE COLUMNS AND THEIR\n",
      "PROPERTIES ==================================================  Table: actor\n",
      "------------   actor_id:     Type: smallint unsigned     Nullable: NO     Key:\n",
      "PRI   first_name:     Type: varchar(45)     Nullable: NO   last_name:     Type:\n",
      "varchar(45)     Nullable: NO     Key: MUL   last_update:     Type: timestamp\n",
      "Nullable: NO  Table: actor_info -----------------   actor_id:     Type: smallint\n",
      "unsigned     Nullable: NO   first_name:     Type: varchar(45)     Nullable: NO\n",
      "last_name:     Type: varchar(45)     Nullable: NO   film_info:     Type: text\n",
      "Nullable: YES  Table: address --------------   address_id:     Type: smallint\n",
      "unsigned     Nullable: NO     Key: PRI   address:     Type: varchar(50)\n",
      "Nullable: NO   address2:     Type: varchar(50)     Nullable: YES   district:\n",
      "Type: varchar(20)     Nullable: NO   city_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: MUL   postal_code:     Type: varchar(10)     Nullable: YES\n",
      "phone:     Type: varchar(20)     Nullable: NO   location:     Type: geometry\n",
      "Nullable: NO     Key: MUL   last_update:     Type: timestamp     Nullable: NO\n",
      "Table: category ---------------   category_id:     Type: tinyint unsigned\n",
      "Nullable: NO     Key: PRI   name:     Type: varchar(25)     Nullable: NO\n",
      "last_update:     Type: timestamp     Nullable: NO  Table: city -----------\n",
      "city_id:     Type: smallint unsigned     Nullable: NO     Key: PRI   city:\n",
      "Type: varchar(50)     Nullable: NO   country_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: MUL   last_update:     Type: timestamp     Nullable: NO\n",
      "Table: country --------------   country_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: PRI   country:     Type: varchar(50)     Nullable: NO\n",
      "last_update:     Type: timestamp     Nullable: NO  Table: customer\n",
      "---------------   customer_id:     Type: smallint unsigned     Nullable: NO\n",
      "Key: PRI   store_id:     Type: tinyint unsigned     Nullable: NO     Key: MUL\n",
      "first_name:     Type: varchar(45)     Nullable: NO   last_name:     Type:\n",
      "varchar(45)     Nullable: NO     Key: MUL   email:     Type: varchar(50)\n",
      "Nullable: YES   address_id:     Type: smallint unsigned     Nullable: NO\n",
      "Key: MUL   active:     Type: tinyint(1)     Nullable: NO   create_date:\n",
      "Type: datetime     Nullable: NO   last_update:     Type: timestamp     Nullable:\n",
      "YES  Table: customer_list --------------------   ID:     Type: smallint unsigned\n",
      "Nullable: NO   name:     Type: varchar(91)     Nullable: YES   address:\n",
      "Type: varchar(50)     Nullable: NO   zip code:     Type: varchar(10)\n",
      "Nullable: YES   phone:     Type: varchar(20)     Nullable: NO   city:     Type:\n",
      "varchar(50)     Nullable: NO   country:     Type: varchar(50)     Nullable: NO\n",
      "notes:     Type: varchar(6)     Nullable: NO   SID:     Type: tinyint unsigned\n",
      "Nullable: NO  Table: customer_rental_info ---------------------------\n",
      "customer_id:     Type: smallint unsigned     Nullable: NO   first_name:\n",
      "Type: varchar(45)     Nullable: NO   last_name:     Type: varchar(45)\n",
      "Nullable: NO   email:     Type: varchar(50)     Nullable: YES   rental_count:\n",
      "Type: bigint     Nullable: NO  Table: customer_rental_payment1\n",
      "-------------------------------   customer_id:     Type: smallint unsigned\n",
      "Nullable: NO   first_name:     Type: varchar(45)     Nullable: NO   last_name:\n",
      "Type: varchar(45)     Nullable: NO   email:     Type: varchar(50)     Nullable:\n",
      "YES   rental_count:     Type: bigint     Nullable: NO   total_amount_paid:\n",
      "Type: decimal(27,2)     Nullable: YES  Table: events -------------   VAERS_ID:\n",
      "Type: int     Nullable: NO     Key: PRI   RECVDATE:     Type: date     Nullable:\n",
      "YES   STATE:     Type: varchar(2)     Nullable: YES   AGE_YRS:     Type: float\n",
      "Nullable: YES   CAGE_YR:     Type: float     Nullable: YES   CAGE_MO:     Type:\n",
      "int     Nullable: YES   SEX:     Type: char(1)     Nullable: YES   RPT_DATE:\n",
      "Type: date     Nullable: YES   SYMPTOM_TEXT:     Type: text     Nullable: YES\n",
      "DIED:     Type: varchar(3)     Nullable: YES   CUR_ILL:     Type: varchar(255)\n",
      "Nullable: YES   HISTORY:     Type: text     Nullable: YES   PRIOR_VAX:     Type:\n",
      "varchar(3)     Nullable: YES   SPLTTYPE:     Type: varchar(50)     Nullable: YES\n",
      "FORM_VERS:     Type: int     Nullable: YES   TODAYS_DATE:     Type: date\n",
      "Nullable: YES   BIRTH_DEFECT:     Type: varchar(3)     Nullable: YES\n",
      "OFC_VISIT:     Type: varchar(3)     Nullable: YES   ER_ED_VISIT:     Type:\n",
      "varchar(3)     Nullable: YES   ALLERGIES:     Type: varchar(255)     Nullable:\n",
      "YES  Table: film -----------   film_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: PRI   title:     Type: varchar(128)     Nullable: NO\n",
      "Key: MUL   description:     Type: text     Nullable: YES   release_year:\n",
      "Type: year     Nullable: YES   language_id:     Type: tinyint unsigned\n",
      "Nullable: NO     Key: MUL   original_language_id:     Type: tinyint unsigned\n",
      "Nullable: YES     Key: MUL   rental_duration:     Type: tinyint unsigned\n",
      "Nullable: NO   rental_rate:     Type: decimal(4,2)     Nullable: NO   length:\n",
      "Type: smallint unsigned     Nullable: YES   replacement_cost:     Type:\n",
      "decimal(5,2)     Nullable: NO   rating:     Type:\n",
      "enum('G','PG','PG-13','R','NC-17')     Nullable: YES   special_features:\n",
      "Type: set('Trailers','Commentaries','Deleted Scenes','Behind the Scenes')\n",
      "Nullable: YES   last_update:     Type: timestamp     Nullable: NO  Table:\n",
      "film_actor -----------------   actor_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: PRI   film_id:     Type: smallint unsigned     Nullable:\n",
      "NO     Key: PRI   last_update:     Type: timestamp     Nullable: NO  Table:\n",
      "film_category --------------------   film_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: PRI   category_id:     Type: tinyint unsigned\n",
      "Nullable: NO     Key: PRI   last_update:     Type: timestamp     Nullable: NO\n",
      "Table: film_list ----------------   FID:     Type: smallint unsigned\n",
      "Nullable: NO   title:     Type: varchar(128)     Nullable: NO   description:\n",
      "Type: text     Nullable: YES   category:     Type: varchar(25)     Nullable: YES\n",
      "price:     Type: decimal(4,2)     Nullable: NO   length:     Type: smallint\n",
      "unsigned     Nullable: YES   rating:     Type:\n",
      "enum('G','PG','PG-13','R','NC-17')     Nullable: YES   actors:     Type: text\n",
      "Nullable: YES  Table: film_text ----------------   film_id:     Type: smallint\n",
      "Nullable: NO     Key: PRI   title:     Type: varchar(255)     Nullable: NO\n",
      "Key: MUL   description:     Type: text     Nullable: YES  Table: inventory\n",
      "----------------   inventory_id:     Type: mediumint unsigned     Nullable: NO\n",
      "Key: PRI   film_id:     Type: smallint unsigned     Nullable: NO     Key: MUL\n",
      "store_id:     Type: tinyint unsigned     Nullable: NO     Key: MUL\n",
      "last_update:     Type: timestamp     Nullable: NO  Table: language\n",
      "---------------   language_id:     Type: tinyint unsigned     Nullable: NO\n",
      "Key: PRI   name:     Type: char(20)     Nullable: NO   last_update:     Type:\n",
      "timestamp     Nullable: NO  Table: nicer_but_slower_film_list\n",
      "---------------------------------   FID:     Type: smallint unsigned\n",
      "Nullable: NO   title:     Type: varchar(128)     Nullable: NO   description:\n",
      "Type: text     Nullable: YES   category:     Type: varchar(25)     Nullable: YES\n",
      "price:     Type: decimal(4,2)     Nullable: NO   length:     Type: smallint\n",
      "unsigned     Nullable: YES   rating:     Type:\n",
      "enum('G','PG','PG-13','R','NC-17')     Nullable: YES   actors:     Type: text\n",
      "Nullable: YES  Table: payment --------------   payment_id:     Type: smallint\n",
      "unsigned     Nullable: NO     Key: PRI   customer_id:     Type: smallint\n",
      "unsigned     Nullable: NO     Key: MUL   staff_id:     Type: tinyint unsigned\n",
      "Nullable: NO     Key: MUL   rental_id:     Type: int     Nullable: YES     Key:\n",
      "MUL   amount:     Type: decimal(5,2)     Nullable: NO   payment_date:     Type:\n",
      "datetime     Nullable: NO   last_update:     Type: timestamp     Nullable: YES\n",
      "Table: rental -------------   rental_id:     Type: int     Nullable: NO     Key:\n",
      "PRI   rental_date:     Type: datetime     Nullable: NO     Key: MUL\n",
      "inventory_id:     Type: mediumint unsigned     Nullable: NO     Key: MUL\n",
      "customer_id:     Type: smallint unsigned     Nullable: NO     Key: MUL\n",
      "return_date:     Type: datetime     Nullable: YES   staff_id:     Type: tinyint\n",
      "unsigned     Nullable: NO     Key: MUL   last_update:     Type: timestamp\n",
      "Nullable: NO  Table: sales_by_film_category -----------------------------\n",
      "category:     Type: varchar(25)     Nullable: NO   total_sales:     Type:\n",
      "decimal(27,2)     Nullable: YES  Table: sales_by_store ---------------------\n",
      "store:     Type: varchar(101)     Nullable: YES   manager:     Type: varchar(91)\n",
      "Nullable: YES   total_sales:     Type: decimal(27,2)     Nullable: YES  Table:\n",
      "staff ------------   staff_id:     Type: tinyint unsigned     Nullable: NO\n",
      "Key: PRI   first_name:     Type: varchar(45)     Nullable: NO   last_name:\n",
      "Type: varchar(45)     Nullable: NO   address_id:     Type: smallint unsigned\n",
      "Nullable: NO     Key: MUL   picture:     Type: blob     Nullable: YES   email:\n",
      "Type: varchar(50)     Nullable: YES   store_id:     Type: tinyint unsigned\n",
      "Nullable: NO     Key: MUL   active:     Type: tinyint(1)     Nullable: NO\n",
      "username:     Type: varchar(16)     Nullable: NO   password:     Type:\n",
      "varchar(40)     Nullable: YES   last_update:     Type: timestamp     Nullable:\n",
      "NO  Table: staff_list -----------------   ID:     Type: tinyint unsigned\n",
      "Nullable: NO   name:     Type: varchar(91)     Nullable: YES   address:\n",
      "Type: varchar(50)     Nullable: NO   zip code:     Type: varchar(10)\n",
      "Nullable: YES   phone:     Type: varchar(20)     Nullable: NO   city:     Type:\n",
      "varchar(50)     Nullable: NO   country:     Type: varchar(50)     Nullable: NO\n",
      "SID:     Type: tinyint unsigned     Nullable: NO  Table: store ------------\n",
      "store_id:     Type: tinyint unsigned     Nullable: NO     Key: PRI\n",
      "manager_staff_id:     Type: tinyint unsigned     Nullable: NO     Key: UNI\n",
      "address_id:     Type: smallint unsigned     Nullable: NO     Key: MUL\n",
      "last_update:     Type: timestamp     Nullable: NO\n",
      "================================================== FOREIGN KEY RELATIONSHIPS\n",
      "==================================================  - address.city_id ->\n",
      "city.city_id - city.country_id -> country.country_id - customer.address_id ->\n",
      "address.address_id - customer.store_id -> store.store_id - film.language_id ->\n",
      "language.language_id - film.original_language_id -> language.language_id -\n",
      "film_actor.actor_id -> actor.actor_id - film_actor.film_id -> film.film_id -\n",
      "film_category.category_id -> category.category_id - film_category.film_id ->\n",
      "film.film_id - inventory.film_id -> film.film_id - inventory.store_id ->\n",
      "store.store_id - payment.customer_id -> customer.customer_id - payment.rental_id\n",
      "-> rental.rental_id - payment.staff_id -> staff.staff_id - rental.customer_id ->\n",
      "customer.customer_id - rental.inventory_id -> inventory.inventory_id -\n",
      "rental.staff_id -> staff.staff_id - staff.address_id -> address.address_id -\n",
      "staff.store_id -> store.store_id - store.address_id -> address.address_id -\n",
      "store.manager_staff_id -> staff.staff_id\n"
     ]
    }
   ],
   "source": [
    "pretty_print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_data_df\",\n",
    "            \"description\": \"Get the data from the database\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sql_query\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"sql_query\"]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to use the OpenAI API with tool calling, and let's include the get_data_df tool\n",
    "\n",
    "def agent(messages):\n",
    "    \n",
    "    # Initialize the OpenAI client\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Make a ChatGPT API call with tool calling\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=tools, # here we pass the tools to the LLM\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message\n",
    "\n",
    "    # Check if the response contains a tool call\n",
    "    if response.tool_calls:\n",
    "        # Process each tool call\n",
    "        for tool_call in response.tool_calls:\n",
    "            # Get the tool call arguments\n",
    "            tool_call_arguments = json.loads(tool_call.function.arguments) # Parse the JSON object to a python dictionary\n",
    "            if tool_call.function.name == \"get_data_df\":\n",
    "                # Here we call the predefined get_weather function and pass the tool call arguments the LLM provided\n",
    "                print(f\"Tool arguments: {tool_call_arguments}\")\n",
    "                return get_data_df(tool_call_arguments[\"sql_query\"])\n",
    "    else:\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI assistant designed to help you with data analysis and queries related to the Sakila database. You can call me Assistant! How can I assist you today?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "user_prompt = \"What is your name?\" # \"What is the current weather in Barcelona?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "response = agent(messages)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Streamlit App\n",
    "\n",
    "Okay, now we have developed all the agent function to be able to create the Sakila Data Agent. Next we have to use this functions in a streamlit app to build the UI to the agent.\n",
    "\n",
    "Use the empty `app.py` file to build the UI to the agent. Copy the `chatbot.py` file from [this repository](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py) and paste it on the `app.py` file and work from there.\n",
    "\n",
    "🍀 **GOOD LUCK!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
